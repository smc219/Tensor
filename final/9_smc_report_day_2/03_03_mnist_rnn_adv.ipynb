{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_03_mnist_rnn_adv.ipynb","provenance":[{"file_id":"1KVIrRYaerKdchfrROqf1c4pNyvIBpcqa","timestamp":1574801930031},{"file_id":"1tn8NhT9hvVDVqVQHodbsTY7KUCAYy_Zj","timestamp":1574798721157},{"file_id":"1nkqVytRmAxDvYJwgoueea8kPBiCXirXw","timestamp":1574791737676},{"file_id":"1S6Wj34C9uOII3Um-OWXlMO-ztX2FTl21","timestamp":1574791677538},{"file_id":"18zcR7miQsixNzxSzeY4NjUAqznVL-9aw","timestamp":1574787092815},{"file_id":"11Z1YxyMnx7r9zk5KucF7zgdrDv7__Q9f","timestamp":1574784450971},{"file_id":"1GyjxF5uw647LcmGSXy4kifN_i6HeGFsQ","timestamp":1574781597038},{"file_id":"1Uaoy1W9KJZ8lWZsmdA-3fLWRb5EAzlYp","timestamp":1574780594576},{"file_id":"1QUNQ432HvAKEa9_3xgxTOJomZdxmi6sQ","timestamp":1574772959831},{"file_id":"12xNbP_2KivhaBh9rhBFD9vqJp56Yjc8T","timestamp":1574770099497},{"file_id":"1inQbH3sHy1w2AnOd8FM8yDJ4ltYO3Rr-","timestamp":1574769467131},{"file_id":"https://github.com/hochaeAidl/ai-middle-course/blob/master/code_templete.ipynb","timestamp":1574766303250}],"collapsed_sections":["Ho6uwOJ9YkfT","wOiaPQ3xgJQC","aD28IHuegUxp","EY3zfzjlgbYj","PUqUyRtngdUC","n9BG8hNUgo0n","fAOKfujLZo94","zMat0-hSzeq_","bmh73SkvAsjd"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YUbrsmxWf04y","colab_type":"text"},"source":["# **실습 3-3 : MNIST RNN Advanced, Bi-directional RNN** \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ho6uwOJ9YkfT"},"source":["## **Import Module**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0trJmd6DjqBZ","outputId":"a1d14f0c-af87-4e50-8ff1-37b6f39abc65","executionInfo":{"status":"ok","timestamp":1575976876470,"user_tz":-540,"elapsed":2075,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","  \n","import tensorflow.keras as keras\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","tf.__version__"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'2.0.0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"wOiaPQ3xgJQC","colab_type":"text"},"source":["## **DataSet**"]},{"cell_type":"markdown","metadata":{"id":"aD28IHuegUxp","colab_type":"text"},"source":["### Load"]},{"cell_type":"code","metadata":{"id":"cC8AS287Hz-9","colab_type":"code","colab":{}},"source":["#(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","sample, sample_label = x_train[0], y_train[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EY3zfzjlgbYj","colab_type":"text"},"source":["## **Model**"]},{"cell_type":"markdown","metadata":{"id":"PUqUyRtngdUC","colab_type":"text"},"source":["### Define"]},{"cell_type":"code","metadata":{"id":"vCAvqXiiDI6X","colab_type":"code","colab":{}},"source":["# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n","# Each input sequence will be of size (28, 28) (height is treated like time).\n","input_dim = 28\n","\n","units = 16\n","output_size = 10  # labels are from 0 to 9\n","\n","## Build the RNN model\n","def model_RNN():\n","  lstm_layer = keras.layers.LSTM(units,     # keras.lyaer.LSTM\n","                     input_shape=(None, input_dim))\n","#\n","  model = keras.models.Sequential(name=\"Basic-RNN\")\n","  model.add(lstm_layer)\n","#  model.add(keras.layers.BatchNormalization())\n","  model.add(keras.layers.Dense(output_size, activation='softmax'))\n","  return model\n","\n","## Build the Bi-RNN model\n","def model_BRNN():\n","  lstm_layer = keras.layers.Bidirectional(  # keras.layers.Bidirectional\n","                  keras.layers.LSTM(units), # LSTM \n","                        input_shape=(None, input_dim))\n","#\n","  model = keras.models.Sequential(name=\"Bidirectional-RNN\")\n","  model.add(lstm_layer)\n","#  model.add(keras.layers.BatchNormalization())\n","  model.add(keras.layers.Dense(output_size, activation='softmax'))\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n9BG8hNUgo0n","colab_type":"text"},"source":["### Compile"]},{"cell_type":"code","metadata":{"id":"EJbIBgLeZp_T","colab_type":"code","outputId":"d26d5539-9a7f-41f8-966c-4ce9634ed462","executionInfo":{"status":"ok","timestamp":1575976879026,"user_tz":-540,"elapsed":4608,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":449}},"source":["# model_R : RNN\n","model_R = model_RNN()\n","model_R.compile(loss='sparse_categorical_crossentropy', \n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","# model_Bi : bi-RNN\n","model_Bi = model_BRNN()\n","model_Bi.compile(loss='sparse_categorical_crossentropy', \n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","model_R.summary()\n","model_Bi.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"Basic-RNN\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 16)                2880      \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                170       \n","=================================================================\n","Total params: 3,050\n","Trainable params: 3,050\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"Bidirectional-RNN\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional (Bidirectional (None, 32)                5760      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                330       \n","=================================================================\n","Total params: 6,090\n","Trainable params: 6,090\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fAOKfujLZo94"},"source":["### Fit"]},{"cell_type":"markdown","metadata":{"id":"wtgvcJnrAdfc","colab_type":"text"},"source":["Epoch 30/30\n","60000/60000 [==============================] - 5s 81us/sample - loss: 0.0992 - accuracy: 0.9701 - val_loss: 0.1091 - val_accuracy: 0.9658\n","CPU times: user 3min 58s, sys: 10.3 s, total: 4min 8s\n","\n","Wall time: 2min 28s (@Edit-Notebook Setting-GPU)"]},{"cell_type":"markdown","metadata":{"id":"1O49BpvHnPXo","colab_type":"text"},"source":["##기록\n","\n","epoch 30\n","batch 128\n","val accuracy: 0.8613\n","\n"]},{"cell_type":"code","metadata":{"id":"kuSVxgwR_n9x","colab_type":"code","outputId":"c324dd1a-da04-4d89-e0e4-764595aa1a24","executionInfo":{"status":"ok","timestamp":1575977276092,"user_tz":-540,"elapsed":401668,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","batch_size = 32\n","history_R = model_R.fit(x_train, y_train,\n","          validation_data=(x_test, y_test),\n","          batch_size=batch_size,\n","          epochs=50)\n","\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 11s 183us/sample - loss: 0.8601 - accuracy: 0.7066 - val_loss: 0.6197 - val_accuracy: 0.7710\n","Epoch 2/50\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.5591 - accuracy: 0.8012 - val_loss: 0.5727 - val_accuracy: 0.8011\n","Epoch 3/50\n","60000/60000 [==============================] - 8s 133us/sample - loss: 0.4998 - accuracy: 0.8215 - val_loss: 0.4951 - val_accuracy: 0.8191\n","Epoch 4/50\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.4648 - accuracy: 0.8339 - val_loss: 0.4665 - val_accuracy: 0.8322\n","Epoch 5/50\n","60000/60000 [==============================] - 8s 132us/sample - loss: 0.4407 - accuracy: 0.8432 - val_loss: 0.4691 - val_accuracy: 0.8274\n","Epoch 6/50\n","60000/60000 [==============================] - 8s 132us/sample - loss: 0.4255 - accuracy: 0.8469 - val_loss: 0.4510 - val_accuracy: 0.8340\n","Epoch 7/50\n","60000/60000 [==============================] - 8s 133us/sample - loss: 0.4111 - accuracy: 0.8519 - val_loss: 0.4320 - val_accuracy: 0.8450\n","Epoch 8/50\n","60000/60000 [==============================] - 8s 133us/sample - loss: 0.4002 - accuracy: 0.8565 - val_loss: 0.4129 - val_accuracy: 0.8508\n","Epoch 9/50\n","60000/60000 [==============================] - 8s 133us/sample - loss: 0.3899 - accuracy: 0.8590 - val_loss: 0.4234 - val_accuracy: 0.8486\n","Epoch 10/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3832 - accuracy: 0.8623 - val_loss: 0.4114 - val_accuracy: 0.8505\n","Epoch 11/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3761 - accuracy: 0.8648 - val_loss: 0.4054 - val_accuracy: 0.8542\n","Epoch 12/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3694 - accuracy: 0.8679 - val_loss: 0.4060 - val_accuracy: 0.8533\n","Epoch 13/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3650 - accuracy: 0.8700 - val_loss: 0.4015 - val_accuracy: 0.8570\n","Epoch 14/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3589 - accuracy: 0.8712 - val_loss: 0.4007 - val_accuracy: 0.8552\n","Epoch 15/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3552 - accuracy: 0.8731 - val_loss: 0.3875 - val_accuracy: 0.8604\n","Epoch 16/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3499 - accuracy: 0.8748 - val_loss: 0.3808 - val_accuracy: 0.8628\n","Epoch 17/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3458 - accuracy: 0.8748 - val_loss: 0.3839 - val_accuracy: 0.8637\n","Epoch 18/50\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.3423 - accuracy: 0.8769 - val_loss: 0.3752 - val_accuracy: 0.8661\n","Epoch 19/50\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.3402 - accuracy: 0.8773 - val_loss: 0.3817 - val_accuracy: 0.8617\n","Epoch 20/50\n","60000/60000 [==============================] - 8s 132us/sample - loss: 0.3365 - accuracy: 0.8781 - val_loss: 0.3742 - val_accuracy: 0.8644\n","Epoch 21/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3329 - accuracy: 0.8809 - val_loss: 0.3790 - val_accuracy: 0.8627\n","Epoch 22/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3310 - accuracy: 0.8807 - val_loss: 0.3902 - val_accuracy: 0.8578\n","Epoch 23/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3281 - accuracy: 0.8823 - val_loss: 0.3683 - val_accuracy: 0.8681\n","Epoch 24/50\n","60000/60000 [==============================] - 8s 129us/sample - loss: 0.3251 - accuracy: 0.8828 - val_loss: 0.3615 - val_accuracy: 0.8728\n","Epoch 25/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.3239 - accuracy: 0.8831 - val_loss: 0.3739 - val_accuracy: 0.8664\n","Epoch 26/50\n","60000/60000 [==============================] - 8s 136us/sample - loss: 0.3214 - accuracy: 0.8842 - val_loss: 0.3616 - val_accuracy: 0.8713\n","Epoch 27/50\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.3198 - accuracy: 0.8849 - val_loss: 0.3667 - val_accuracy: 0.8651\n","Epoch 28/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3174 - accuracy: 0.8860 - val_loss: 0.3681 - val_accuracy: 0.8654\n","Epoch 29/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3154 - accuracy: 0.8865 - val_loss: 0.3658 - val_accuracy: 0.8713\n","Epoch 30/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3139 - accuracy: 0.8872 - val_loss: 0.3608 - val_accuracy: 0.8694\n","Epoch 31/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3124 - accuracy: 0.8867 - val_loss: 0.3543 - val_accuracy: 0.8751\n","Epoch 32/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3108 - accuracy: 0.8876 - val_loss: 0.3535 - val_accuracy: 0.8739\n","Epoch 33/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3082 - accuracy: 0.8893 - val_loss: 0.3581 - val_accuracy: 0.8727\n","Epoch 34/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3068 - accuracy: 0.8895 - val_loss: 0.3598 - val_accuracy: 0.8716\n","Epoch 35/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.3057 - accuracy: 0.8897 - val_loss: 0.3584 - val_accuracy: 0.8725\n","Epoch 36/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.3040 - accuracy: 0.8896 - val_loss: 0.3530 - val_accuracy: 0.8746\n","Epoch 37/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.3038 - accuracy: 0.8904 - val_loss: 0.3496 - val_accuracy: 0.8779\n","Epoch 38/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3030 - accuracy: 0.8910 - val_loss: 0.3601 - val_accuracy: 0.8737\n","Epoch 39/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.3011 - accuracy: 0.8913 - val_loss: 0.3582 - val_accuracy: 0.8731\n","Epoch 40/50\n","60000/60000 [==============================] - 8s 133us/sample - loss: 0.3004 - accuracy: 0.8906 - val_loss: 0.3472 - val_accuracy: 0.8773\n","Epoch 41/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.2990 - accuracy: 0.8916 - val_loss: 0.3492 - val_accuracy: 0.8755\n","Epoch 42/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.2971 - accuracy: 0.8920 - val_loss: 0.3489 - val_accuracy: 0.8739\n","Epoch 43/50\n","60000/60000 [==============================] - 8s 129us/sample - loss: 0.2969 - accuracy: 0.8929 - val_loss: 0.3513 - val_accuracy: 0.8729\n","Epoch 44/50\n","60000/60000 [==============================] - 8s 129us/sample - loss: 0.2960 - accuracy: 0.8924 - val_loss: 0.3477 - val_accuracy: 0.8754\n","Epoch 45/50\n","60000/60000 [==============================] - 8s 129us/sample - loss: 0.2954 - accuracy: 0.8926 - val_loss: 0.3472 - val_accuracy: 0.8773\n","Epoch 46/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.2939 - accuracy: 0.8927 - val_loss: 0.3470 - val_accuracy: 0.8778\n","Epoch 47/50\n","60000/60000 [==============================] - 8s 128us/sample - loss: 0.2925 - accuracy: 0.8941 - val_loss: 0.3467 - val_accuracy: 0.8755\n","Epoch 48/50\n","60000/60000 [==============================] - 8s 129us/sample - loss: 0.2914 - accuracy: 0.8938 - val_loss: 0.3512 - val_accuracy: 0.8758\n","Epoch 49/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.2904 - accuracy: 0.8938 - val_loss: 0.3428 - val_accuracy: 0.8800\n","Epoch 50/50\n","60000/60000 [==============================] - 8s 130us/sample - loss: 0.2905 - accuracy: 0.8939 - val_loss: 0.3622 - val_accuracy: 0.8680\n","CPU times: user 8min 6s, sys: 37.5 s, total: 8min 43s\n","Wall time: 6min 37s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QboR9RI8kBGP","colab_type":"code","outputId":"6b1d87e4-2bf5-4bb0-ad67-53f99f4feb9b","executionInfo":{"status":"ok","timestamp":1575977276096,"user_tz":-540,"elapsed":401663,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(np.max(history_R.history['val_accuracy']))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.88\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7KbIreYLd6gj","colab_type":"text"},"source":["[Advanced model]  \n","Epoch 30/30\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.0484 - accuracy: 0.9852 - val_loss: 0.0572 - val_accuracy: 0.9818\n","CPU times: user 6min 54s, sys: 23.7 s, total: 7min 18s\n","\n","Wall time: 4min 9s (@Edit-Notebook Setting-GPU)"]},{"cell_type":"code","metadata":{"id":"WeRSZVJGzd0-","colab_type":"code","outputId":"f9ac9fba-4426-4b5b-835c-1adaa002efb9","executionInfo":{"status":"error","timestamp":1575968110590,"user_tz":-540,"elapsed":504732,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":647}},"source":["%%time\n","# advanced model\n","history_Bi = model_Bi.fit(x_train, y_train,\n","          validation_data=(x_test, y_test),\n","          batch_size=batch_size,\n","          epochs=30)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/30\n","60000/60000 [==============================] - 15s 249us/sample - loss: 0.7333 - accuracy: 0.7467 - val_loss: 0.5295 - val_accuracy: 0.8110\n","Epoch 2/30\n","60000/60000 [==============================] - 12s 202us/sample - loss: 0.4705 - accuracy: 0.8292 - val_loss: 0.4626 - val_accuracy: 0.8327\n","Epoch 3/30\n","60000/60000 [==============================] - 12s 200us/sample - loss: 0.4179 - accuracy: 0.8476 - val_loss: 0.4297 - val_accuracy: 0.8454\n","Epoch 4/30\n","60000/60000 [==============================] - 12s 201us/sample - loss: 0.3897 - accuracy: 0.8588 - val_loss: 0.4159 - val_accuracy: 0.8502\n","Epoch 5/30\n","60000/60000 [==============================] - 12s 203us/sample - loss: 0.3735 - accuracy: 0.8652 - val_loss: 0.4046 - val_accuracy: 0.8564\n","Epoch 6/30\n","60000/60000 [==============================] - 12s 202us/sample - loss: 0.3586 - accuracy: 0.8696 - val_loss: 0.3922 - val_accuracy: 0.8598\n","Epoch 7/30\n","60000/60000 [==============================] - 12s 204us/sample - loss: 0.3501 - accuracy: 0.8735 - val_loss: 0.3810 - val_accuracy: 0.8643\n","Epoch 8/30\n","60000/60000 [==============================] - 12s 201us/sample - loss: 0.3408 - accuracy: 0.8762 - val_loss: 0.3705 - val_accuracy: 0.8683\n","Epoch 9/30\n","60000/60000 [==============================] - 12s 202us/sample - loss: 0.3333 - accuracy: 0.8794 - val_loss: 0.3683 - val_accuracy: 0.8666\n","Epoch 10/30\n","60000/60000 [==============================] - 12s 208us/sample - loss: 0.3273 - accuracy: 0.8818 - val_loss: 0.3639 - val_accuracy: 0.8700\n","Epoch 11/30\n","60000/60000 [==============================] - 12s 205us/sample - loss: 0.3204 - accuracy: 0.8834 - val_loss: 0.3640 - val_accuracy: 0.8683\n","Epoch 12/30\n","60000/60000 [==============================] - 12s 202us/sample - loss: 0.3162 - accuracy: 0.8853 - val_loss: 0.3550 - val_accuracy: 0.8706\n","Epoch 13/30\n","60000/60000 [==============================] - 12s 203us/sample - loss: 0.3115 - accuracy: 0.8873 - val_loss: 0.3456 - val_accuracy: 0.8768\n","Epoch 14/30\n","60000/60000 [==============================] - 12s 202us/sample - loss: 0.3074 - accuracy: 0.8875 - val_loss: 0.3477 - val_accuracy: 0.8757\n","Epoch 15/30\n","60000/60000 [==============================] - 12s 202us/sample - loss: 0.3025 - accuracy: 0.8907 - val_loss: 0.3468 - val_accuracy: 0.8768\n","Epoch 16/30\n","60000/60000 [==============================] - 12s 202us/sample - loss: 0.2997 - accuracy: 0.8913 - val_loss: 0.3476 - val_accuracy: 0.8740\n","Epoch 17/30\n","42048/60000 [====================>.........] - ETA: 3s - loss: 0.2930 - accuracy: 0.8925"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zMat0-hSzeq_"},"source":["## **Analysis**"]},{"cell_type":"markdown","metadata":{"id":"bmh73SkvAsjd","colab_type":"text"},"source":["### Plot"]},{"cell_type":"code","metadata":{"id":"EGhsQm-i_sZx","colab_type":"code","colab":{}},"source":["print(history_Bi.history.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-_idMKYwKVqX","colab_type":"code","colab":{}},"source":["losses_Bi = history_Bi.history['loss']\n","val_loss_Bi = history_Bi.history['val_loss']\n","losses_R = history_R.history['loss']\n","val_loss_R = history_R.history['val_loss']\n","\n","acc_Bi = history_Bi.history['accuracy']\n","val_acc_Bi = history_Bi.history['val_accuracy']\n","acc_R = history_R.history['accuracy']\n","val_acc_R = history_R.history['val_accuracy']\n","\n","plt.figure(figsize=(10, 16))\n","plt.subplot(2, 1, 1)\n","plt.semilogy(losses_Bi, label='loss_Bi')\n","plt.semilogy(val_loss_Bi, label='val_loss_Bi')\n","plt.semilogy(losses_R, label='loss_R')\n","plt.semilogy(val_loss_R, label='val_loss_R')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.title(\"LOSS\")\n","\n","plt.subplot(2, 1, 2)\n","plt.semilogy(acc_Bi, label='accuracy_Bi')\n","plt.semilogy(val_acc_Bi, label='val_accur_Bi')\n","plt.semilogy(acc_R, label='accuracy_R')\n","plt.semilogy(val_acc_R, label='val_accur_R')\n","#plt.ylim(0.8,1)\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.title(\"Accuracy\")\n","plt.show()  \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnaUZbi_hIHw","colab_type":"text"},"source":["## **실습 과제**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k6LTcavDi72w"},"source":["### 과제 1. `model_R.fit()`에서 `batch_size=`와 `epochs='값을 조정하여 최적의 값을 찾아 보자\n","#### -- batch_size 를 32,128,512,1024로 바꾸면서 accuracy값을 비교해 보자 \n","#### -- 최고의 결과를 낼 batch_size를 예상하고 그 이유를 적어보자 \n","#### -- 실험 결과와 예상결과를 비교하고, 분석하자 : \n","\n","\n","\n"," "]},{"cell_type":"markdown","metadata":{"id":"9Yo6WolHgNtA","colab_type":"text"},"source":["### 과제 2. epochs를 30,100,200등으로 바꾸어 보자 \n","####-- batch_size도 같이 조정하여 최적의 조건을 찾아보자 : \n"]},{"cell_type":"markdown","metadata":{"id":"TvHqVWUdlmM1","colab_type":"text"},"source":["##과제 1 및 2답안\n","\n","batch_size가 작은 방향으로 갔을 때 조금 더 좋은 값으로 가지 않을까 싶습니다.\n","\n","돌려봤을 때 64 가량에서 효율이 제일 괜찮게 나왔고, batch size가 200 선 일때 88.38로 valid accuracy가 가장 높은 값이 나오는 것을 확인했습니다. epoch와 batch 사이즈 간에도 상관관계가 있어 보이는 것이, batch_size가 64보다 작은 경우에는 epoch를 늘렸을 때 그 결과값이 87.08~88.12(batch_size==32)로 뚜렷한 증가추세를 보인 반면 64보다 큰 경우에는 85.18~87.15(batch_size==1024)로 상대적으로 증가 추세가 둔감화되는 것을 확인할 수 있었습니다. \n","\n","즉 데이터를 학습시키는 총량이 정해져 있을 때 batch_size와 epoch간에 적정한 최적값이 있다는 것을 알 수 있고, 이 경우에는 batch_size가 64, epoch가 200인 경우임을 알 수 있다.\n","\n","다만 이 이상 학습 시켰을 때 더 이상 효용을 보지 못할 것으로 보인다. 그 근거로 들 수 있는 것 중 하나는 학습 효율의 향상이다. batch_size가 64, epoch가 150일 때 valid accuracy가 88.34, epoch가 200일때 valid accuracy가 88.35로 사실상 학습 효율이 임계에 달했음을 확인할 수 있다.\n","\n","이를 통해서 알 수 있는 것은 각 데이터간에 loss function을 계산해 cost를 도출해내는 과정에서 본 데이터의 경우에는 batch_size를 64로 할때 그 오차를 최소화할 수 있다는 것이고, epoch의 경우에는 사실상 200선이 최대로, 그 이상으로 올라갈 경우에는 학습 효율을 기대할 수 없을 것으로 보이며, 오히려 오버 피팅이 일어날 것으로 생각된다.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KLiuncqMsd4Y","colab_type":"text"},"source":[""]}]}