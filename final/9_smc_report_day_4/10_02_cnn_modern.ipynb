{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10_02_cnn_modern.ipynb","provenance":[{"file_id":"1Y4VAwlnRVeZq-IkSseEWR0HCCeYHRB2G","timestamp":1574949261254},{"file_id":"1Uaoy1W9KJZ8lWZsmdA-3fLWRb5EAzlYp","timestamp":1574780594576},{"file_id":"1QUNQ432HvAKEa9_3xgxTOJomZdxmi6sQ","timestamp":1574772959831},{"file_id":"12xNbP_2KivhaBh9rhBFD9vqJp56Yjc8T","timestamp":1574770099497},{"file_id":"1inQbH3sHy1w2AnOd8FM8yDJ4ltYO3Rr-","timestamp":1574769467131},{"file_id":"https://github.com/hochaeAidl/ai-middle-course/blob/master/code_templete.ipynb","timestamp":1574766303250}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YUbrsmxWf04y","colab_type":"text"},"source":["# **실습 5-1 : Modern CNN**"]},{"cell_type":"markdown","metadata":{"id":"CfwO3tnWf_nY","colab_type":"text"},"source":["## **Import Module**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0trJmd6DjqBZ","outputId":"c03cec7e-2f4e-4d41-c6b6-c126efc97458","executionInfo":{"status":"ok","timestamp":1576462514723,"user_tz":-540,"elapsed":3429,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["%tensorflow_version 2.x\n","\n","import tensorflow as tf\n","#import tensorflow.keras as keras\n","from tensorflow.keras import models, datasets\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D\n","from tensorflow.keras.layers import MaxPool2D, MaxPool1D\n","from tensorflow.keras.layers import Dropout, BatchNormalization\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","tf.__version__"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'2.0.0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"wOiaPQ3xgJQC","colab_type":"text"},"source":["## **DataSet**"]},{"cell_type":"markdown","metadata":{"id":"wMjfCbJFk1Ue","colab_type":"text"},"source":["## 2 `TensorFlow datasets` 사용하기"]},{"cell_type":"markdown","metadata":{"id":"YpSGNZu-sGBu","colab_type":"text"},"source":["### 2.1 tf.keras.utils.get_file()   \n","# -- TF에서 제공되는 DataSet을 지정된 위치에서 읽어, colab에 압축 풀어 저장하기  \n"," -- DataSet Document https://www.tensorflow.org/datasets/catalog/overview 에서 URL 참조"]},{"cell_type":"code","metadata":{"id":"vtEVRmdf9YfJ","colab_type":"code","outputId":"bad69141-dca9-4d03-c6e3-264caedf3dd5","executionInfo":{"status":"ok","timestamp":1576462520422,"user_tz":-540,"elapsed":4440,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import pathlib\n","data_dir = tf.keras.utils.get_file(\n","    origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n","    fname='flower_photos', untar=True)\n","data_dir = pathlib.Path(data_dir)\n","print (data_dir)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n","228818944/228813984 [==============================] - 1s 0us/step\n","/root/.keras/datasets/flower_photos\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9JCz0dEqqgmA","colab_type":"text"},"source":["### 2.2 저장된 이미지를 `ImageDataGenerator()`로 준비하기 "]},{"cell_type":"markdown","metadata":{"id":"eKmlIZlZIsfF","colab_type":"text"},"source":["### 1.2 check images"]},{"cell_type":"code","metadata":{"id":"uuT7u7uTGJM4","colab_type":"code","colab":{}},"source":["# 지정 폴더 아래에 있는 모든 *.jpg 파일의 수\n","#  및 폴더명 목록을 리턴  \n","def check_dir(d_path):\n","  img_count = len(list(d_path.glob('*/*.jpg')))\n","  c_name = np.array([item.name for item in d_path.glob('*') if item.name != \"LICENSE.txt\"])\n","  return img_count, c_name, len(c_name)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cSR3yvFyhBzv","colab_type":"code","outputId":"6a6449a0-a1b6-401a-b640-b650ce8f474f","executionInfo":{"status":"ok","timestamp":1576145262775,"user_tz":-540,"elapsed":3074,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# check_dir()로 폴더명과 이미지 숫자 확인\n","image_count, CLASS_NAMES, class_num = check_dir(data_dir)\n","\n","print('image_count: {}\\nclasses: {}'.format(image_count, CLASS_NAMES))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["image_count: 3670\n","classes: ['roses' 'tulips' 'dandelion' 'sunflowers' 'daisy']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHoGnJlyZrnK","colab_type":"code","colab":{}},"source":["# input image size 지정 ***\n","im_size = 112"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMXscRYCJe6J","colab_type":"code","outputId":"4ae96a00-8f97-4633-ba25-357cb2de93c2","executionInfo":{"status":"ok","timestamp":1576145262777,"user_tz":-540,"elapsed":3062,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# image generator for unziped directory \n","# The 1./255 is to convert from uint8 to float32 in range [0,1].\n","image_generator = (\n","    tf.keras.preprocessing.image.ImageDataGenerator(\n","        #width_shift_range=0.05,\n","        #height_shift_range=0.05,\n","        horizontal_flip=True, \n","        vertical_flip=True,\n","        #rotation_range=30,\n","        #zoom_range=0.1,\n","        brightness_range=[0.8,1.2],\n","        validation_split=0.2,\n","        rescale=1./255))\n","\n","# Batch size 지정 ***\n","batch_n = 128\n","\n","# generate train dataset\n","train_data_gen = image_generator.flow_from_directory(\n","                      directory=str(data_dir),\n","                      batch_size=batch_n,\n","                      target_size=(im_size, im_size),\n","                      classes = list(CLASS_NAMES),\n","                      subset='training'\n","                      )\n","\n","test_data_gen = image_generator.flow_from_directory(\n","                      directory=str(data_dir),\n","                      batch_size=batch_n,\n","                      target_size=(im_size, im_size),\n","                      classes = list(CLASS_NAMES),\n","                      subset='validation'\n","                      )\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 2939 images belonging to 5 classes.\n","Found 731 images belonging to 5 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UYy1gNp-6oLu","colab_type":"code","colab":{}},"source":["4/uQGAGgfgwyrmxCDLc9ZT0Zgm2hNcpNbHTmXo98RjTbBywY9xvkCUVpU"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EY3zfzjlgbYj","colab_type":"text"},"source":["## **Model**"]},{"cell_type":"markdown","metadata":{"id":"PUqUyRtngdUC","colab_type":"text"},"source":["### Define"]},{"cell_type":"markdown","metadata":{"id":"0Mvz8Gu6lrkf","colab_type":"text"},"source":["### Model_A define: Dropout 사용 model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"txF_6kHF71Tr","outputId":"8dff6bd7-3b2c-4b3a-c9b3-ef41b48e4ebd","executionInfo":{"status":"ok","timestamp":1576145264303,"user_tz":-540,"elapsed":4579,"user":{"displayName":"석민창","photoUrl":"","userId":"14498853270593904544"}},"colab":{"base_uri":"https://localhost:8080/","height":845}},"source":["def model_cnn_basic():\n","  model = models.Sequential()\n","  # conv 1\n","  model.add(Conv2D(64,3,padding='same',activation='relu',input_shape=(im_size,im_size,3)))\n","  model.add(Conv2D(64,3,padding='same',activation='relu',input_shape=(im_size,im_size,3)))\n","  model.add(BatchNormalization(momentum=0.85))\n","  model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n","  \n","  # conv 2\n","  model.add(Conv2D(128, 3, padding='same', activation='relu'))\n","  model.add(Conv2D(128, 3, padding='same', activation='relu'))\n","  model.add(BatchNormalization(momentum=0.85))\n","  model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n","  # conv 3\n","  model.add(Conv2D(512, 3, padding='same', activation='relu'))\n","  #model.add(Conv2D(256, 3, padding='same', activation='relu'))\n","  #model.add(Conv2D(256, 3, padding='same', activation='relu'))\n","  model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n","  model.add(BatchNormalization(momentum=0.85))\n","  # conv 4\n","  model.add(Conv2D(256, 3, padding='same', activation='relu'))\n","  #model.add(Conv2D(256, 3, padding='same', activation='relu'))\n","  model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n","  model.add(BatchNormalization(momentum=0.85))\n","  # conv 4\n","  model.add(Conv2D(64, 3, padding='same', activation='relu'))\n","  #model.add(Conv2D(256, 3, padding='same', activation='relu'))\n","  #model.add(Conv2D(256, 3, padding='same', activation='relu'))\n","  model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n","  model.add(BatchNormalization(momentum=0.85))\n","  # Dense layers\n","  model.add(Flatten(name='flatten'))\n","  #model.add(Dense(1024, activation='relu', name='dense_1024'))\n","  model.add(Dense(2, activation='softmax', name='dense_10'))\n","\n","  return model\n","\n","model_basic = model_cnn_basic()\n","model_basic.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 112, 112, 64)      1792      \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 112, 112, 64)      36928     \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 112, 112, 64)      256       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 55, 55, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 55, 55, 128)       73856     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 55, 55, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 55, 55, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 27, 27, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 27, 27, 512)       590336    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 13, 13, 512)       0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 13, 13, 512)       2048      \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 13, 13, 256)       1179904   \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 6, 6, 256)         1024      \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 6, 6, 64)          147520    \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 2, 2, 64)          0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 2, 2, 64)          256       \n","_________________________________________________________________\n","flatten (Flatten)            (None, 256)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 5)                 1285      \n","=================================================================\n","Total params: 2,183,301\n","Trainable params: 2,181,253\n","Non-trainable params: 2,048\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wwrqskp8ZRA2","colab":{}},"source":["# def model_cnn_dropout():\n","#   model = models.Sequential()\n","#   # conv 1\n","#   model.add(Conv2D(64,3,padding='same',activation='relu',input_shape=(im_size,im_size,3)))\n","#   model.add(Dropout(rate=0.3))                          # DO\n","#   model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","#   # conv 2\n","#   model.add(Conv2D(128, 3, padding='same', activation='relu'))\n","#   model.add(Dropout(rate=0.3))                          # DO\n","#   model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","#   # conv 3\n","#   model.add(Conv2D(256, 3, padding='same', activation='relu'))\n","#   model.add(Dropout(rate=0.3))                          # DO\n","#   model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","#   # dense layers\n","#   model.add(Flatten(name='flatten'))\n","#   model.add(Dense(1024, activation='relu', name='dense_1024'))\n","#   model.add(Dense(len(CLASS_NAMES), activation='softmax', name='dense_10'))\n","\n","#   return model\n","\n","# model_DO = model_cnn_dropout()\n","\n","# #model_DO.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zaF3AiENl7aS","colab_type":"text"},"source":["### Model_B define: Batch Normalization 사용 model"]},{"cell_type":"code","metadata":{"id":"FNUgJxiHeL9x","colab_type":"code","colab":{}},"source":["# def model_cnn_batchnormal():\n","#   model = tf.keras.models.Sequential()\n","#   # conv 1\n","#   model.add(Conv2D(32,3,padding='same',activation='relu',input_shape=(im_size,im_size,3))) \n","#   model.add(BatchNormalization(momentum=0.85))             # BN\n","#   model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","#   # conv 2\n","#   model.add(Conv2D(64, 3, padding='same', activation='relu'))\n","#   model.add(BatchNormalization(momentum=0.85))             # BN\n","#   model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","#   # conv 3\n","#   model.add(Conv2D(128, 3, padding='same', activation='relu')) \n","#   model.add(BatchNormalization(momentum=0.85))             # BN\n","#   model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","#   # conv 4\n","#   model.add(Conv2D(128, 3, padding='same', activation='relu')) \n","#   model.add(BatchNormalization(momentum=0.85))             # BN\n","#   model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","#   # dense layers\n","#   model.add(Flatten(name='flatten'))\n","#   model.add(Dense(1024, activation='relu', name='dense_1024'))\n","#   model.add(Dense(len(CLASS_NAMES), activation='softmax', name='dense_10'))\n","\n","#   return model\n","\n","# model_BN=model_cnn_batchnormal()\n","\n","# #model_BN.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aACwVs7QgmLq","colab_type":"text"},"source":["### Compile"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"woHSnFcU8qhb","colab":{}},"source":["model_basic.compile(optimizer='adam',\n","              #loss='sparse_categorical_crossentropy',\n","              loss='categorical_crossentropy',\n","              metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hP7ohoahKZ-K","colab_type":"code","colab":{}},"source":["# model_DO.compile(optimizer='adam',\n","#               #loss='sparse_categorical_crossentropy',\n","#               loss='categorical_crossentropy',\n","#               metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EjVZ-mBFiWAd","colab":{}},"source":["# model_BN.compile(optimizer='adam',\n","#               #loss='sparse_categorical_crossentropy',\n","#               loss='categorical_crossentropy',\n","#               metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n9BG8hNUgo0n","colab_type":"text"},"source":["### Fit"]},{"cell_type":"code","metadata":{"id":"TaUq13N0_0uW","colab_type":"code","colab":{}},"source":["# batch_n = 512 move to generator\n","epoch_n = 100"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7KbIreYLd6gj","colab_type":"text"},"source":["Epoch 20/20\n","60000/60000 [==============================] - 5s 80us/sample - loss: 0.0276 - accuracy: 0.9911\n","CPU times: user 1min 7s, sys: 30.2 s, total: 1min 38s   \n","Wall time: 1min 40\n","(@Notebook Setting/GPU)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3TSmq7N1EpVJ","colab":{}},"source":["# %%time\n","# # reset data generator\n","# train_data_gen.reset()\n","# test_data_gen.reset()\n","\n","# # fit_gen\n","# history_BN = model_BN.fit_generator(train_data_gen, \n","#                         epochs=epoch_n,\n","#                         validation_data=test_data_gen\n","#                         )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N0rhj42r8y5q","outputId":"bda39bd1-d7dd-4d17-ae23-e59d10a8e1ae","executionInfo":{"status":"ok","timestamp":1576085609188,"user_tz":-540,"elapsed":543816,"user":{"displayName":"hochae Jeong","photoUrl":"","userId":"15751602523246647728"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","# reset data generator\n","train_data_gen.reset()\n","test_data_gen.reset()\n","\n","history_basic = model_basic.fit_generator(train_data_gen, \n","                        epochs=epoch_n,\n","                        validation_data=test_data_gen)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","23/23 [==============================] - 19s 821ms/step - loss: 1.2575 - acc: 0.5396 - val_loss: 1.5857 - val_acc: 0.3174\n","Epoch 2/100\n","23/23 [==============================] - 14s 607ms/step - loss: 0.8627 - acc: 0.6611 - val_loss: 1.2173 - val_acc: 0.5622\n","Epoch 3/100\n","23/23 [==============================] - 14s 621ms/step - loss: 0.7456 - acc: 0.7043 - val_loss: 1.0253 - val_acc: 0.5992\n","Epoch 4/100\n","23/23 [==============================] - 14s 617ms/step - loss: 0.6857 - acc: 0.7302 - val_loss: 0.9152 - val_acc: 0.6484\n","Epoch 5/100\n","23/23 [==============================] - 14s 612ms/step - loss: 0.6252 - acc: 0.7574 - val_loss: 0.9287 - val_acc: 0.6840\n","Epoch 6/100\n","23/23 [==============================] - 14s 605ms/step - loss: 0.5811 - acc: 0.7870 - val_loss: 0.9040 - val_acc: 0.6430\n","Epoch 7/100\n","23/23 [==============================] - 14s 614ms/step - loss: 0.5558 - acc: 0.7833 - val_loss: 0.9147 - val_acc: 0.6717\n","Epoch 8/100\n","23/23 [==============================] - 14s 609ms/step - loss: 0.4989 - acc: 0.8139 - val_loss: 0.9579 - val_acc: 0.6854\n","Epoch 9/100\n","23/23 [==============================] - 14s 612ms/step - loss: 0.4631 - acc: 0.8292 - val_loss: 0.6419 - val_acc: 0.7592\n","Epoch 10/100\n","23/23 [==============================] - 14s 603ms/step - loss: 0.4344 - acc: 0.8394 - val_loss: 0.7818 - val_acc: 0.7073\n","Epoch 11/100\n","23/23 [==============================] - 14s 606ms/step - loss: 0.4107 - acc: 0.8476 - val_loss: 0.8344 - val_acc: 0.6621\n","Epoch 12/100\n","23/23 [==============================] - 14s 623ms/step - loss: 0.3997 - acc: 0.8557 - val_loss: 0.6282 - val_acc: 0.7715\n","Epoch 13/100\n","23/23 [==============================] - 14s 608ms/step - loss: 0.3487 - acc: 0.8704 - val_loss: 0.8348 - val_acc: 0.7059\n","Epoch 14/100\n","23/23 [==============================] - 14s 609ms/step - loss: 0.3586 - acc: 0.8683 - val_loss: 0.7307 - val_acc: 0.7497\n","Epoch 15/100\n","23/23 [==============================] - 14s 618ms/step - loss: 0.3434 - acc: 0.8727 - val_loss: 0.8212 - val_acc: 0.7127\n","Epoch 16/100\n","23/23 [==============================] - 14s 619ms/step - loss: 0.3292 - acc: 0.8741 - val_loss: 0.7062 - val_acc: 0.7579\n","Epoch 17/100\n","23/23 [==============================] - 14s 618ms/step - loss: 0.2965 - acc: 0.8979 - val_loss: 0.7584 - val_acc: 0.7291\n","Epoch 18/100\n","23/23 [==============================] - 14s 607ms/step - loss: 0.2730 - acc: 0.9071 - val_loss: 0.8121 - val_acc: 0.7497\n","Epoch 19/100\n","23/23 [==============================] - 14s 617ms/step - loss: 0.2661 - acc: 0.9013 - val_loss: 0.6155 - val_acc: 0.7811\n","Epoch 20/100\n","23/23 [==============================] - 14s 621ms/step - loss: 0.2234 - acc: 0.9224 - val_loss: 0.6950 - val_acc: 0.7907\n","Epoch 21/100\n","23/23 [==============================] - 14s 614ms/step - loss: 0.2141 - acc: 0.9245 - val_loss: 0.6491 - val_acc: 0.7921\n","Epoch 22/100\n","23/23 [==============================] - 14s 601ms/step - loss: 0.1897 - acc: 0.9364 - val_loss: 0.8478 - val_acc: 0.7456\n","Epoch 23/100\n","23/23 [==============================] - 14s 622ms/step - loss: 0.1914 - acc: 0.9255 - val_loss: 0.6819 - val_acc: 0.7852\n","Epoch 24/100\n","23/23 [==============================] - 14s 616ms/step - loss: 0.1822 - acc: 0.9432 - val_loss: 0.7336 - val_acc: 0.7674\n","Epoch 25/100\n","23/23 [==============================] - 14s 610ms/step - loss: 0.1519 - acc: 0.9520 - val_loss: 0.6856 - val_acc: 0.7962\n","Epoch 26/100\n","23/23 [==============================] - 14s 609ms/step - loss: 0.1407 - acc: 0.9513 - val_loss: 0.8690 - val_acc: 0.7592\n","Epoch 27/100\n","23/23 [==============================] - 14s 615ms/step - loss: 0.1342 - acc: 0.9558 - val_loss: 0.6151 - val_acc: 0.8071\n","Epoch 28/100\n","23/23 [==============================] - 14s 611ms/step - loss: 0.1292 - acc: 0.9568 - val_loss: 0.8254 - val_acc: 0.7606\n","Epoch 29/100\n","23/23 [==============================] - 14s 621ms/step - loss: 0.1256 - acc: 0.9578 - val_loss: 0.7781 - val_acc: 0.7921\n","Epoch 30/100\n","23/23 [==============================] - 14s 604ms/step - loss: 0.1117 - acc: 0.9605 - val_loss: 0.6987 - val_acc: 0.7893\n","Epoch 31/100\n","23/23 [==============================] - 14s 611ms/step - loss: 0.0988 - acc: 0.9690 - val_loss: 0.7596 - val_acc: 0.7825\n","Epoch 32/100\n","23/23 [==============================] - 14s 612ms/step - loss: 0.1092 - acc: 0.9609 - val_loss: 0.7038 - val_acc: 0.8030\n","Epoch 33/100\n","23/23 [==============================] - 14s 613ms/step - loss: 0.0866 - acc: 0.9707 - val_loss: 0.6775 - val_acc: 0.8194\n","Epoch 34/100\n","23/23 [==============================] - 14s 619ms/step - loss: 0.0817 - acc: 0.9755 - val_loss: 0.9297 - val_acc: 0.7415\n","Epoch 35/100\n","23/23 [==============================] - 14s 600ms/step - loss: 0.0807 - acc: 0.9769 - val_loss: 0.6911 - val_acc: 0.7934\n","Epoch 36/100\n","23/23 [==============================] - 14s 609ms/step - loss: 0.0668 - acc: 0.9796 - val_loss: 0.8056 - val_acc: 0.7756\n","Epoch 37/100\n","23/23 [==============================] - 14s 614ms/step - loss: 0.0604 - acc: 0.9854 - val_loss: 0.7746 - val_acc: 0.7811\n","Epoch 38/100\n","23/23 [==============================] - 14s 603ms/step - loss: 0.0737 - acc: 0.9772 - val_loss: 0.7787 - val_acc: 0.7756\n","Epoch 39/100\n","23/23 [==============================] - 14s 608ms/step - loss: 0.0675 - acc: 0.9782 - val_loss: 0.8048 - val_acc: 0.8003\n","Epoch 40/100\n","23/23 [==============================] - 14s 614ms/step - loss: 0.0527 - acc: 0.9843 - val_loss: 0.7450 - val_acc: 0.8030\n","Epoch 41/100\n","23/23 [==============================] - 14s 608ms/step - loss: 0.0484 - acc: 0.9843 - val_loss: 0.7483 - val_acc: 0.8140\n","Epoch 42/100\n","23/23 [==============================] - 14s 607ms/step - loss: 0.0515 - acc: 0.9833 - val_loss: 0.7340 - val_acc: 0.7934\n","Epoch 43/100\n","23/23 [==============================] - 14s 605ms/step - loss: 0.0474 - acc: 0.9864 - val_loss: 0.7203 - val_acc: 0.8057\n","Epoch 44/100\n","23/23 [==============================] - 14s 602ms/step - loss: 0.0383 - acc: 0.9915 - val_loss: 0.7563 - val_acc: 0.7921\n","Epoch 45/100\n","23/23 [==============================] - 14s 610ms/step - loss: 0.0399 - acc: 0.9874 - val_loss: 0.7425 - val_acc: 0.8044\n","Epoch 46/100\n","23/23 [==============================] - 14s 620ms/step - loss: 0.0401 - acc: 0.9895 - val_loss: 0.8078 - val_acc: 0.8153\n","Epoch 47/100\n","23/23 [==============================] - 14s 614ms/step - loss: 0.0379 - acc: 0.9891 - val_loss: 0.7977 - val_acc: 0.7907\n","Epoch 48/100\n","23/23 [==============================] - 14s 622ms/step - loss: 0.0297 - acc: 0.9925 - val_loss: 0.8443 - val_acc: 0.7934\n","Epoch 49/100\n","23/23 [==============================] - 14s 621ms/step - loss: 0.0233 - acc: 0.9946 - val_loss: 1.0055 - val_acc: 0.7921\n","Epoch 50/100\n","23/23 [==============================] - 14s 610ms/step - loss: 0.0183 - acc: 0.9976 - val_loss: 0.7808 - val_acc: 0.8098\n","Epoch 51/100\n","23/23 [==============================] - 14s 610ms/step - loss: 0.0177 - acc: 0.9963 - val_loss: 0.8098 - val_acc: 0.8098\n","Epoch 52/100\n","23/23 [==============================] - 14s 615ms/step - loss: 0.0300 - acc: 0.9935 - val_loss: 1.0415 - val_acc: 0.7839\n","Epoch 53/100\n","23/23 [==============================] - 14s 613ms/step - loss: 0.0452 - acc: 0.9857 - val_loss: 0.8377 - val_acc: 0.8016\n","Epoch 54/100\n","23/23 [==============================] - 14s 610ms/step - loss: 0.0506 - acc: 0.9826 - val_loss: 0.8416 - val_acc: 0.8030\n","Epoch 55/100\n","23/23 [==============================] - 14s 620ms/step - loss: 0.0437 - acc: 0.9860 - val_loss: 0.8345 - val_acc: 0.7975\n","Epoch 56/100\n","23/23 [==============================] - 14s 626ms/step - loss: 0.0536 - acc: 0.9843 - val_loss: 0.9187 - val_acc: 0.7839\n","Epoch 57/100\n","23/23 [==============================] - 14s 621ms/step - loss: 0.0485 - acc: 0.9843 - val_loss: 0.8210 - val_acc: 0.7893\n","Epoch 58/100\n","23/23 [==============================] - 14s 615ms/step - loss: 0.0375 - acc: 0.9891 - val_loss: 0.8189 - val_acc: 0.8030\n","Epoch 59/100\n","23/23 [==============================] - 14s 610ms/step - loss: 0.0341 - acc: 0.9918 - val_loss: 0.8646 - val_acc: 0.7880\n","Epoch 60/100\n","23/23 [==============================] - 14s 620ms/step - loss: 0.0365 - acc: 0.9884 - val_loss: 0.8266 - val_acc: 0.7866\n","Epoch 61/100\n","23/23 [==============================] - 14s 620ms/step - loss: 0.0384 - acc: 0.9888 - val_loss: 0.7776 - val_acc: 0.8222\n","Epoch 62/100\n","23/23 [==============================] - 14s 620ms/step - loss: 0.0307 - acc: 0.9912 - val_loss: 0.8162 - val_acc: 0.8003\n","Epoch 63/100\n","23/23 [==============================] - 14s 620ms/step - loss: 0.0415 - acc: 0.9871 - val_loss: 0.9469 - val_acc: 0.7866\n","Epoch 64/100\n","23/23 [==============================] - 14s 619ms/step - loss: 0.0347 - acc: 0.9884 - val_loss: 0.8441 - val_acc: 0.7975\n","Epoch 65/100\n","23/23 [==============================] - 14s 617ms/step - loss: 0.0230 - acc: 0.9929 - val_loss: 0.8628 - val_acc: 0.8085\n","Epoch 66/100\n","23/23 [==============================] - 14s 619ms/step - loss: 0.0158 - acc: 0.9952 - val_loss: 0.7550 - val_acc: 0.8167\n","Epoch 67/100\n","23/23 [==============================] - 14s 625ms/step - loss: 0.0194 - acc: 0.9939 - val_loss: 0.8686 - val_acc: 0.8071\n","Epoch 68/100\n","23/23 [==============================] - 14s 618ms/step - loss: 0.0254 - acc: 0.9942 - val_loss: 0.8865 - val_acc: 0.8044\n","Epoch 69/100\n","23/23 [==============================] - 14s 621ms/step - loss: 0.0226 - acc: 0.9949 - val_loss: 0.7995 - val_acc: 0.8194\n","Epoch 70/100\n","23/23 [==============================] - 14s 620ms/step - loss: 0.0255 - acc: 0.9929 - val_loss: 0.8825 - val_acc: 0.8030\n","Epoch 71/100\n","23/23 [==============================] - 14s 623ms/step - loss: 0.0260 - acc: 0.9922 - val_loss: 1.0301 - val_acc: 0.7975\n","Epoch 72/100\n","23/23 [==============================] - 14s 629ms/step - loss: 0.0223 - acc: 0.9922 - val_loss: 0.9307 - val_acc: 0.8181\n","Epoch 73/100\n","23/23 [==============================] - 14s 622ms/step - loss: 0.0161 - acc: 0.9969 - val_loss: 0.8626 - val_acc: 0.8126\n","Epoch 74/100\n","23/23 [==============================] - 14s 621ms/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.7338 - val_acc: 0.8140\n","Epoch 75/100\n","23/23 [==============================] - 14s 616ms/step - loss: 0.0206 - acc: 0.9939 - val_loss: 0.7776 - val_acc: 0.8317\n","Epoch 76/100\n","22/23 [===========================>..] - ETA: 0s - loss: 0.0252 - acc: 0.9897"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-_idMKYwKVqX","colab_type":"code","colab":{}},"source":["%%time\n","# reset data generator\n","train_data_gen.reset()\n","test_data_gen.reset()\n","\n","history_DO = model_DO.fit_generator(train_data_gen, \n","                        epochs=epoch_n,\n","                        validation_data=test_data_gen\n","                        )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"koce91rPKo6U","colab_type":"text"},"source":["Epoch 20/20\n","60000/60000 [==============================] - 4s 73us/sample - loss: 2.1958e-04 - accuracy: 1.0000\n","CPU times: user 1min 1s, sys: 25.2 s, total: 1min 26s   \n","Wall time: 1min 27s (@Notebook Setting/GPU)"]},{"cell_type":"markdown","metadata":{"id":"v7Bf90ATg98K","colab_type":"text"},"source":["## **Analysis**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EkAYMpMu4xhk","colab":{}},"source":["print(np.max(history_basic.history['val_acc']))\n","print(np.max(history_DO.history['val_acc']))\n","print(np.max(history_BN.history['val_acc']))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RfIQ7DoNJgg9","colab_type":"text"},"source":["0.7116  \n","0.7257  \n","0.7268"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"99gDq4ujEqMY"},"source":["### Plot"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"esddMQeDEqMT","colab":{}},"source":["history_basic.history.keys()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7nz6QmPFEqMD","colab":{}},"source":["loss = history_basic.history['loss']\n","epochs = range(1, len(loss)+1)\n","\n","plt.figure(figsize=(10, 10))\n","plt.subplot(2, 1, 1)\n","plt.title('Validation Loss')\n","plt.semilogy(epochs, history_basic.history['val_loss'], 'b', label='CNN')\n","plt.semilogy(epochs, history_DO.history['val_loss'], 'r', label='CNN_DO')\n","plt.semilogy(epochs, history_BN.history['val_loss'], 'g', label='CNN_BN')\n","plt.grid(True)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","#plt.ylim([0.0, 0.6])\n","plt.legend(loc='best')\n","\n","plt.subplot(2, 1, 2)\n","plt.title('Validation Accuray')\n","plt.semilogy(epochs, history_basic.history['val_acc'], 'b', label='CNN')\n","plt.semilogy(epochs, history_DO.history['val_acc'], 'r', label='CNN_DO')\n","plt.semilogy(epochs, history_BN.history['val_acc'], 'g', label='CNN_BN')\n","plt.grid(True)\n","plt.ylabel('Accuracy')\n","plt.ylim([0.5, 0.9])\n","plt.legend(loc='best')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnaUZbi_hIHw","colab_type":"text"},"source":["## **실습 과제**"]},{"cell_type":"markdown","metadata":{"id":"o5QEUAIbhVUQ","colab_type":"text"},"source":["### 과제1 성능 개선을 위해서 다양한 실험이 필요해 보인다.\n","#### -- Layer / Feature map 숫자 변경, \n","#### -- dropout / batch normalization 위치 및 숫자 변경,\n","#### -- batch size, epoch 변경을 통해 모델을 최적화 해 보자 \n","#### -- 조별로 최고의 성능을 달성한 모델의 구조와 주요 hyper-parameter 및 최고 val_acc를 기록하자 : \n"]},{"cell_type":"markdown","metadata":{"id":"nt1WRfDkiAOK","colab_type":"text"},"source":["A, B, C 세 조로 나누어서 진행하였다.\n","\n","가장 높은 결과가 나온 곳은 B조로, 83.17이 나왔으며 epoch 100, batch_size = 128, Layer는 다섯 층으로 구성되었다.\n","\n","해당 조가 레이어를 구성한 방식은 VGG와 유사하였다. Conv를 두단으로 쌓았으며, 레이어를 다층으로 구성하였다."]},{"cell_type":"code","metadata":{"id":"0EQ6NGaMkNbM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}